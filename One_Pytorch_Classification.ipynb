{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------- pip install torchvision-------------------------\n",
    "\n",
    "# in this example we going to develop a classifier using torch python library and \n",
    "# writing the complete rutine (architecture, pre-processing, processing, validation and prediction) from the scratch\n",
    "#lets start then importung principal librearies:\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "# now lets import our dataset tis dataset comes from AWS\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usando cpu\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: 48000\n",
      "training val: 6000\n",
      "training test: 6000\n"
     ]
    }
   ],
   "source": [
    "# generate the new directory for datasets\n",
    "data_mnist=datasets.MNIST(\n",
    "    root= 'datos', # where root is the root directry on which where we are\n",
    "    train= True, \n",
    "    download= True, \n",
    "    transform= ToTensor()\n",
    ")\n",
    "#now we have our 60k data items available and transformed to tensors using ToTensor\n",
    "#have GPU?\n",
    "device=(\n",
    "    'cuda' if torch.cuda.is_available()\n",
    "    else 'cpu'\n",
    ")\n",
    "print(f'usando {device}')\n",
    "# in this case \"device\" is the CUDA variable for GPU when is available, but \n",
    "# for now we'll working using CPU only\n",
    "\n",
    "rows, cols = 3, 3\n",
    "#Lets see our data content:\n",
    "figure=plt.figure(figsize=(8,8))\n",
    "for i in range(1, cols*rows +1):\n",
    "    sample_id=torch.randint(len(data_mnist), size=(1,)).item()\n",
    "    img, lebel= data_mnist[sample_id]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(str(lebel))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img.squeeze(), cmap='CMRmap')\n",
    "plt.show()\n",
    "\n",
    "#training, validation and test datasets (80%, 10%, 10%): we need to create 3 partitions over the actual dataset to achive our goals. To do so...\n",
    "torch.manual_seed(123) #lets take the randomness control\n",
    "#now we can recreate the model independently of the running times.\n",
    "\n",
    "train, val, test=torch.utils.data.random_split(\n",
    "    data_mnist, [0.8 ,0.1, 0.1]\n",
    ")\n",
    "print(f'training set: {len(train)}')\n",
    "print(f'training val: {len(val)}')\n",
    "print(f'training test: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuralnet(\n",
      "  (flatit): Flatten(start_dim=1, end_dim=-1)\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
      "    (3): Softmax(dim=1)\n",
      "  )\n",
      ")\n",
      "The number of parameters in the neural network architecture is 39760\n"
     ]
    }
   ],
   "source": [
    "#----------------------architecture of our neural Network!!---------------------------------------\n",
    "#as any NN doesn't accept any type of images. a nn accept vectores only, \n",
    "# then the first vector it's ging to have 28X28 elements i.e. 784 elements (flaten)\n",
    "#hide layer Nlayer + RELU (15 nodes) last layer 10 nodes softmax\n",
    "#In pytorch includ int transformers, we use nn module\n",
    "\n",
    "#A N Y \n",
    "# neural network architecture is actually a sublass/class of nn.Module\n",
    "#alwais have to add 2 METHODES to this new C L A S S : \n",
    "\n",
    "# 1.- init methode (it defines the actual architecture of the neural network)\n",
    "# 2.- \"forward methode\" (tells us how each predition will be generated)\n",
    "\n",
    "# import torch.nn as nn\n",
    "#create Methode INIT by using def in Class definition\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class neuralnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(neuralnet, self).__init__()\n",
    "        \n",
    "        # Aplanar la imagen de entrada de 28x28 a un vector de 784 elementos\n",
    "        self.flatit = nn.Flatten()\n",
    "        \n",
    "        # Definir las capas de la red neuronal\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(28*28, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 10),\n",
    "            nn.Softmax(dim=1)  # Softmax en la dimensión de las clases\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Procesar la entrada a través de la red\n",
    "        x = self.flatit(x)\n",
    "        logits = self.net(x)\n",
    "        return logits\n",
    "\n",
    "# Crear una instancia de la red neuronal\n",
    "model = neuralnet().to(device)\n",
    "print(model)\n",
    "\n",
    "# Calcular el número de parámetros en la red neuronal\n",
    "t = sum(p.numel() for p in model.parameters())\n",
    "print(f'The number of parameters in the neural network architecture is {t}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'int'>\n",
      "we procced to transform int type into tensor to be properly processed by te network...\n",
      "now our lbl is a <class 'torch.Tensor'>\n",
      "tensor([[0.0882, 0.0946, 0.1077, 0.0941, 0.1117, 0.1264, 0.0906, 0.0994, 0.0972,\n",
      "         0.0901]], grad_fn=<SoftmaxBackward0>)\n",
      "logits:tensor([[0.0882, 0.0946, 0.1077, 0.0941, 0.1117, 0.1264, 0.0906, 0.0994, 0.0972,\n",
      "         0.0901]], grad_fn=<SoftmaxBackward0>)\n",
      "predicted category: 5\n",
      "actual category: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#forward propagation:\n",
    "# is the frst predition we gonna have and its not going to be really good itis like this because we need additional tools like back propagation and the gradiant descending/ce\n",
    "img, lbl=train[201]\n",
    "print(type(img))\n",
    "print(type(lbl))\n",
    "print('we procced to transform int type into tensor to be properly processed by te network...')\n",
    "lbl=torch.tensor(lbl).reshape(1)\n",
    "print(f'now our lbl is a {type(lbl)}')\n",
    "\n",
    "img, lbl = img.to(device), lbl.to(device)\n",
    "logits=model(img)\n",
    "print(logits)\n",
    "\n",
    "y_predict=logits.argmax(1)\n",
    "# ypredict\n",
    "plt.imshow(img.cpu().squeeze(), cmap='CMRmap_r');\n",
    "print(f'logits:{logits}')\n",
    "print(f'predicted category: {y_predict[0]}')\n",
    "print(f'actual category: {lbl[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2762, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Back propagation:\n",
    "fn_loss=nn.CrossEntropyLoss()\n",
    "optimizer= torch.optim.SGD(model.parameters(), lr=0.3) #gradient descending, learning rate of 30%\n",
    "loss=fn_loss(logits, lbl)\n",
    "print(loss)\n",
    "#now lets calculate de gradients of the loss i.e (calculate the change of the loss regarding to model parameters)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batchsize=500\n",
    "\n",
    "train_loader=DataLoader(\n",
    "    dataset=train, \n",
    "    batch_size=batchsize, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader=DataLoader(\n",
    "    dataset=val,\n",
    "    batch_size=batchsize,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #training yn validation of the model\n",
    "# #lets take our forward and back propagation and set it in a loop for to iterate it\n",
    "# #hiperparameters...\n",
    "# learning_rate=0.1\n",
    "# epochs=15 #\"the epoch the number of time we want to execute forward-backward\"\n",
    "# #lets build our loss function\n",
    "# fn_loss=nn.CrossEntropyLoss()\n",
    "# optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "\tLoss: 1.708395 [    0/48000]\n",
      "\tLoss: 1.716877 [ 5000/48000]\n",
      "\tLoss: 1.695567 [10000/48000]\n",
      "\tLoss: 1.695331 [15000/48000]\n",
      "\tLoss: 1.694444 [20000/48000]\n",
      "\tLoss: 1.710031 [25000/48000]\n",
      "\tLoss: 1.710716 [30000/48000]\n",
      "\tLoss: 1.662679 [35000/48000]\n",
      "\tLoss: 1.675488 [40000/48000]\n",
      "\tLoss: 1.696534 [45000/48000]\n",
      "Accuracy/Loss (average)\n",
      "\t\tAccuracy: 80.7% | Loss: 1.695058\n",
      "Validation Accuracy/Loss (average)\n",
      "\t\tAccuracy: 80.0% | Loss: 1.697580\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "\tLoss: 1.683122 [    0/48000]\n",
      "\tLoss: 1.682792 [ 5000/48000]\n",
      "\tLoss: 1.685802 [10000/48000]\n",
      "\tLoss: 1.695770 [15000/48000]\n",
      "\tLoss: 1.708096 [20000/48000]\n",
      "\tLoss: 1.680927 [25000/48000]\n",
      "\tLoss: 1.680437 [30000/48000]\n",
      "\tLoss: 1.681267 [35000/48000]\n",
      "\tLoss: 1.685398 [40000/48000]\n",
      "\tLoss: 1.665774 [45000/48000]\n",
      "Accuracy/Loss (average)\n",
      "\t\tAccuracy: 81.1% | Loss: 1.683955\n",
      "Validation Accuracy/Loss (average)\n",
      "\t\tAccuracy: 80.4% | Loss: 1.688694\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "\tLoss: 1.672865 [    0/48000]\n",
      "\tLoss: 1.663271 [ 5000/48000]\n",
      "\tLoss: 1.667378 [10000/48000]\n",
      "\tLoss: 1.669656 [15000/48000]\n",
      "\tLoss: 1.687419 [20000/48000]\n",
      "\tLoss: 1.676624 [25000/48000]\n",
      "\tLoss: 1.675019 [30000/48000]\n",
      "\tLoss: 1.698407 [35000/48000]\n",
      "\tLoss: 1.676669 [40000/48000]\n",
      "\tLoss: 1.662289 [45000/48000]\n",
      "Accuracy/Loss (average)\n",
      "\t\tAccuracy: 81.4% | Loss: 1.676085\n",
      "Validation Accuracy/Loss (average)\n",
      "\t\tAccuracy: 80.5% | Loss: 1.682217\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "\tLoss: 1.646525 [    0/48000]\n",
      "\tLoss: 1.673650 [ 5000/48000]\n",
      "\tLoss: 1.676242 [10000/48000]\n",
      "\tLoss: 1.675005 [15000/48000]\n",
      "\tLoss: 1.672817 [20000/48000]\n",
      "\tLoss: 1.664843 [25000/48000]\n",
      "\tLoss: 1.688151 [30000/48000]\n",
      "\tLoss: 1.652871 [35000/48000]\n",
      "\tLoss: 1.672220 [40000/48000]\n",
      "\tLoss: 1.674183 [45000/48000]\n",
      "Accuracy/Loss (average)\n",
      "\t\tAccuracy: 81.7% | Loss: 1.670052\n",
      "Validation Accuracy/Loss (average)\n",
      "\t\tAccuracy: 80.7% | Loss: 1.677091\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "\tLoss: 1.654238 [    0/48000]\n",
      "\tLoss: 1.653182 [ 5000/48000]\n",
      "\tLoss: 1.648003 [10000/48000]\n",
      "\tLoss: 1.647521 [15000/48000]\n",
      "\tLoss: 1.665313 [20000/48000]\n",
      "\tLoss: 1.675459 [25000/48000]\n",
      "\tLoss: 1.674711 [30000/48000]\n",
      "\tLoss: 1.665199 [35000/48000]\n",
      "\tLoss: 1.696562 [40000/48000]\n",
      "\tLoss: 1.665258 [45000/48000]\n",
      "Accuracy/Loss (average)\n",
      "\t\tAccuracy: 81.9% | Loss: 1.665270\n",
      "Validation Accuracy/Loss (average)\n",
      "\t\tAccuracy: 80.9% | Loss: 1.673494\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "\tLoss: 1.645623 [    0/48000]\n",
      "\tLoss: 1.666245 [ 5000/48000]\n",
      "\tLoss: 1.680020 [10000/48000]\n",
      "\tLoss: 1.679899 [15000/48000]\n",
      "\tLoss: 1.648754 [20000/48000]\n",
      "\tLoss: 1.641037 [25000/48000]\n",
      "\tLoss: 1.658449 [30000/48000]\n",
      "\tLoss: 1.691147 [35000/48000]\n",
      "\tLoss: 1.692096 [40000/48000]\n",
      "\tLoss: 1.678453 [45000/48000]\n",
      "Accuracy/Loss (average)\n",
      "\t\tAccuracy: 82.1% | Loss: 1.661414\n",
      "Validation Accuracy/Loss (average)\n",
      "\t\tAccuracy: 81.2% | Loss: 1.669889\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "\tLoss: 1.653572 [    0/48000]\n",
      "\tLoss: 1.654916 [ 5000/48000]\n",
      "\tLoss: 1.687974 [10000/48000]\n",
      "\tLoss: 1.659561 [15000/48000]\n",
      "\tLoss: 1.672143 [20000/48000]\n",
      "\tLoss: 1.672164 [25000/48000]\n",
      "\tLoss: 1.647701 [30000/48000]\n",
      "\tLoss: 1.643580 [35000/48000]\n",
      "\tLoss: 1.648084 [40000/48000]\n",
      "\tLoss: 1.676194 [45000/48000]\n",
      "Accuracy/Loss (average)\n",
      "\t\tAccuracy: 82.3% | Loss: 1.658112\n",
      "Validation Accuracy/Loss (average)\n",
      "\t\tAccuracy: 81.3% | Loss: 1.667232\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "\tLoss: 1.697759 [    0/48000]\n",
      "\tLoss: 1.648121 [ 5000/48000]\n",
      "\tLoss: 1.671223 [10000/48000]\n",
      "\tLoss: 1.648569 [15000/48000]\n",
      "\tLoss: 1.646436 [20000/48000]\n",
      "\tLoss: 1.650426 [25000/48000]\n",
      "\tLoss: 1.659206 [30000/48000]\n",
      "\tLoss: 1.680676 [35000/48000]\n",
      "\tLoss: 1.650161 [40000/48000]\n",
      "\tLoss: 1.656665 [45000/48000]\n",
      "Accuracy/Loss (average)\n",
      "\t\tAccuracy: 82.4% | Loss: 1.655329\n",
      "Validation Accuracy/Loss (average)\n",
      "\t\tAccuracy: 81.3% | Loss: 1.664635\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "\tLoss: 1.650554 [    0/48000]\n",
      "\tLoss: 1.656868 [ 5000/48000]\n",
      "\tLoss: 1.658377 [10000/48000]\n",
      "\tLoss: 1.645772 [15000/48000]\n",
      "\tLoss: 1.629894 [20000/48000]\n",
      "\tLoss: 1.664562 [25000/48000]\n",
      "\tLoss: 1.649640 [30000/48000]\n",
      "\tLoss: 1.650303 [35000/48000]\n",
      "\tLoss: 1.650721 [40000/48000]\n",
      "\tLoss: 1.652233 [45000/48000]\n",
      "Accuracy/Loss (average)\n",
      "\t\tAccuracy: 82.6% | Loss: 1.652847\n",
      "Validation Accuracy/Loss (average)\n",
      "\t\tAccuracy: 81.5% | Loss: 1.662430\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "\tLoss: 1.658899 [    0/48000]\n",
      "\tLoss: 1.641074 [ 5000/48000]\n",
      "\tLoss: 1.633520 [10000/48000]\n",
      "\tLoss: 1.664499 [15000/48000]\n",
      "\tLoss: 1.655574 [20000/48000]\n",
      "\tLoss: 1.645038 [25000/48000]\n",
      "\tLoss: 1.621286 [30000/48000]\n",
      "\tLoss: 1.656298 [35000/48000]\n",
      "\tLoss: 1.634521 [40000/48000]\n",
      "\tLoss: 1.640876 [45000/48000]\n",
      "Accuracy/Loss (average)\n",
      "\t\tAccuracy: 82.7% | Loss: 1.650676\n",
      "Validation Accuracy/Loss (average)\n",
      "\t\tAccuracy: 81.5% | Loss: 1.660999\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "\tLoss: 1.667952 [    0/48000]\n",
      "\tLoss: 1.628397 [ 5000/48000]\n",
      "\tLoss: 1.643552 [10000/48000]\n",
      "\tLoss: 1.676230 [15000/48000]\n",
      "\tLoss: 1.663776 [20000/48000]\n",
      "\tLoss: 1.622561 [25000/48000]\n",
      "\tLoss: 1.679455 [30000/48000]\n",
      "\tLoss: 1.641240 [35000/48000]\n",
      "\tLoss: 1.640305 [40000/48000]\n",
      "\tLoss: 1.646770 [45000/48000]\n",
      "Accuracy/Loss (average)\n",
      "\t\tAccuracy: 82.8% | Loss: 1.648747\n",
      "Validation Accuracy/Loss (average)\n",
      "\t\tAccuracy: 81.6% | Loss: 1.659248\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "\tLoss: 1.659588 [    0/48000]\n",
      "\tLoss: 1.646817 [ 5000/48000]\n",
      "\tLoss: 1.655455 [10000/48000]\n",
      "\tLoss: 1.624206 [15000/48000]\n",
      "\tLoss: 1.659384 [20000/48000]\n",
      "\tLoss: 1.654252 [25000/48000]\n",
      "\tLoss: 1.631450 [30000/48000]\n",
      "\tLoss: 1.642838 [35000/48000]\n",
      "\tLoss: 1.662928 [40000/48000]\n",
      "\tLoss: 1.654962 [45000/48000]\n",
      "Accuracy/Loss (average)\n",
      "\t\tAccuracy: 82.9% | Loss: 1.647041\n",
      "Validation Accuracy/Loss (average)\n",
      "\t\tAccuracy: 81.7% | Loss: 1.657528\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "\tLoss: 1.656143 [    0/48000]\n",
      "\tLoss: 1.663248 [ 5000/48000]\n",
      "\tLoss: 1.643568 [10000/48000]\n",
      "\tLoss: 1.635076 [15000/48000]\n",
      "\tLoss: 1.635503 [20000/48000]\n",
      "\tLoss: 1.658167 [25000/48000]\n",
      "\tLoss: 1.640214 [30000/48000]\n",
      "\tLoss: 1.641380 [35000/48000]\n",
      "\tLoss: 1.645327 [40000/48000]\n",
      "\tLoss: 1.634313 [45000/48000]\n",
      "Accuracy/Loss (average)\n",
      "\t\tAccuracy: 83.0% | Loss: 1.645424\n",
      "Validation Accuracy/Loss (average)\n",
      "\t\tAccuracy: 81.8% | Loss: 1.656308\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "\tLoss: 1.615446 [    0/48000]\n",
      "\tLoss: 1.638423 [ 5000/48000]\n",
      "\tLoss: 1.643093 [10000/48000]\n",
      "\tLoss: 1.646176 [15000/48000]\n",
      "\tLoss: 1.639266 [20000/48000]\n",
      "\tLoss: 1.646538 [25000/48000]\n",
      "\tLoss: 1.660038 [30000/48000]\n",
      "\tLoss: 1.659189 [35000/48000]\n",
      "\tLoss: 1.659052 [40000/48000]\n",
      "\tLoss: 1.668698 [45000/48000]\n",
      "Accuracy/Loss (average)\n",
      "\t\tAccuracy: 83.1% | Loss: 1.643963\n",
      "Validation Accuracy/Loss (average)\n",
      "\t\tAccuracy: 81.7% | Loss: 1.655320\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "\tLoss: 1.632125 [    0/48000]\n",
      "\tLoss: 1.615151 [ 5000/48000]\n",
      "\tLoss: 1.651039 [10000/48000]\n",
      "\tLoss: 1.653477 [15000/48000]\n",
      "\tLoss: 1.623952 [20000/48000]\n",
      "\tLoss: 1.668502 [25000/48000]\n",
      "\tLoss: 1.644485 [30000/48000]\n",
      "\tLoss: 1.696988 [35000/48000]\n",
      "\tLoss: 1.646578 [40000/48000]\n",
      "\tLoss: 1.627478 [45000/48000]\n",
      "Accuracy/Loss (average)\n",
      "\t\tAccuracy: 83.2% | Loss: 1.642637\n",
      "Validation Accuracy/Loss (average)\n",
      "\t\tAccuracy: 81.7% | Loss: 1.654132\n",
      "Training and validation completed!\n"
     ]
    }
   ],
   "source": [
    "# Training and validation of the model\n",
    "# Let's take our forward and backward propagation and set it in a loop to iterate it\n",
    "# Hyperparameters...\n",
    "learning_rate = 0.1\n",
    "epochs = 15  # \"The epoch is the number of times we want to execute forward-backward\"\n",
    "# Let's build our loss function\n",
    "fn_loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# The best practice is to generate two principal functions: one to train and one more for the validation then set them into the 10 for loop\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    train_size = len(dataloader.dataset)\n",
    "    nbatches = len(dataloader)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loss_accum, accuracy_accum = 0, 0\n",
    "\n",
    "    for nbatch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        logits = model(X)\n",
    "        loss = loss_fn(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss_accum += loss.item()\n",
    "        accuracy_accum += (logits.argmax(1) == y).type(torch.float).sum().item()\n",
    "        \n",
    "        if nbatch % 10 == 0:\n",
    "            ndata = nbatch * len(X)\n",
    "            print(f'\\tLoss: {loss.item():>7f} [{ndata:>5d}/{train_size:>5d}]')\n",
    "\n",
    "    loss_train = loss_accum / nbatches\n",
    "    accuracy_train = accuracy_accum / train_size\n",
    "    print(f'Accuracy/Loss (average)')\n",
    "    print(f'\\t\\tAccuracy: {(100 * accuracy_train):>0.1f}% | Loss: {loss_train:>8f}')\n",
    "\n",
    "def validate_loop(dataloader, model, loss_fn):\n",
    "    val_size = len(dataloader.dataset)\n",
    "    nbatches = len(dataloader)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_accum, accuracy_accum = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            loss = loss_fn(logits, y)\n",
    "\n",
    "            loss_accum += loss.item()\n",
    "            accuracy_accum += (logits.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    loss_val = loss_accum / nbatches\n",
    "    accuracy_val = accuracy_accum / val_size\n",
    "    print(f'Validation Accuracy/Loss (average)')\n",
    "    print(f'\\t\\tAccuracy: {(100 * accuracy_val):>0.1f}% | Loss: {loss_val:>8f}')\n",
    "\n",
    "# Main training loop\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch+1}\\n-------------------------------')\n",
    "    train_loop(train_loader, model, fn_loss, optimizer)\n",
    "    validate_loop(val_loader, model, fn_loss)\n",
    "print('Training and validation completed!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
